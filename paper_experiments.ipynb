{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import kaczrank, cautiousrank, plot_average_w_ci, kr_itercount, noisykaczrank\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import rankdata\n",
    "%matplotlib inline\n",
    "from choix import *\n",
    "import numba\n",
    "from numba import jit\n",
    "\n",
    "def get_ranking(vec):\n",
    "    \"\"\"Return the ranking associated with a vector of ratings.\"\"\"\n",
    "    return(rankdata(vec)-1).astype(int)\n",
    "\n",
    "def hamdist(v,w):\n",
    "    \"\"\"Returns the Hamming distance between two vectors.\"\"\"\n",
    "    return np.sum(np.abs(v-w) > 1e-10)\n",
    "\n",
    "def k_dist(v,w,k):\n",
    "    \"\"\"Returns the k-distance between two vectors.\"\"\"\n",
    "    return np.sum(np.abs(v-w) > k + 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adj_mat(true_rank, make_comps = False, p=0):\n",
    "    \"\"\"\n",
    "    Build incidence matrix for pairwise comparisons.\n",
    "    \n",
    "    Parameters:\n",
    "    true_rank: array, vector of true rankings from which to build an incidence matrix.\n",
    "    make_comps: bool, whether to also return list of pairwise comparisons.\n",
    "    p: float, probability of incidence matrix containing flipped pairs.\n",
    "    \n",
    "    Returns:\n",
    "    A: array, incidence matrix\n",
    "    comps (if make_comps): list of pairwise comparisons\n",
    "    \"\"\"\n",
    "    n = len(true_rank)\n",
    "\n",
    "    A = np.zeros((int(n*(n-1)/2)+1, n))\n",
    "\n",
    "    t=0\n",
    "    comps = []\n",
    "    for i in tqdm(range(n),leave=False):\n",
    "        for j in range(i+1,n):\n",
    "            \n",
    "            flip = 1\n",
    "            if np.random.rand() < p:\n",
    "                flip = -1\n",
    "            \n",
    "            if flip*true_rank[i] >= flip*true_rank[j]:\n",
    "                \n",
    "                A[t,i] = -1\n",
    "                A[t,j] = 1\n",
    "                t+=1\n",
    "\n",
    "                if make_comps:\n",
    "                    comps.append((j,i))\n",
    "            else:\n",
    "\n",
    "                A[t,i] = 1\n",
    "                A[t,j] = -1\n",
    "                \n",
    "                t+=1\n",
    "                \n",
    "                if make_comps:\n",
    "                    comps.append((i,j))\n",
    "\n",
    "    if make_comps:\n",
    "        return A, comps\n",
    "       \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 1 : KaczRank applied to a full information system with no noise.\n",
    "\n",
    "n = 50\n",
    "n_iters = 10000\n",
    "n_trials = 20\n",
    "eps = 1e-5\n",
    "true_vals = np.random.rand(n)\n",
    "true_rank = get_ranking(true_vals)\n",
    "A, comps = build_adj_mat(true_rank, make_comps = True)\n",
    "x_init=np.random.rand(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_results = []\n",
    "\n",
    "k1dist_results = []\n",
    "k5dist_results = []\n",
    "k10dist_results = []\n",
    "\n",
    "ls_results = []\n",
    "skr_results = []\n",
    "for i in tqdm(range(n_trials)):\n",
    "    iters, ranks = kaczrank(A, eps, x_init=x_init.copy(), n_iters = n_iters, verbose=True)\n",
    "    #s_iters, s_ranks = simple_cautiousrank(n, comps, eps, x_init=x_init.copy(), alpha=4, n_iters = n_iters, verbose=True)\n",
    "    \n",
    "    ham_results.append([hamdist(ranks[i,:], true_rank) for i in range(ranks.shape[0])])\n",
    "    #skr_results.append([hamdist(s_ranks[i,:], true_rank) for i in range(ranks.shape[0])])\n",
    "    \n",
    "    \n",
    "    k1dist_results.append([k_dist(ranks[i,:], true_rank, 1) for i in range(ranks.shape[0])])\n",
    "    k5dist_results.append([k_dist(ranks[i,:], true_rank, 5) for i in range(ranks.shape[0])])\n",
    "    k10dist_results.append([k_dist(ranks[i,:], true_rank, 10) for i in range(ranks.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hamming distance plot\n",
    "plt.clf()\n",
    "plot_average_w_ci(ham_results, x = range(n_iters+1), n_lines = 2, line_i = 0, label=\"KaczRank\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Hamming distance from true ranking\")\n",
    "plt.xlim(left=0, right=n_iters+1)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(\"full_info_ham_dist_new.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-distance plot\n",
    "plt.clf()\n",
    "plot_average_w_ci(k1dist_results, label = '$k=1$', line_i = 0, x = range(n_iters+1), n_lines = 3)\n",
    "plot_average_w_ci(k5dist_results, label = '$k=5$', line_i = 1, x = range(n_iters+1), n_lines = 3)\n",
    "plot_average_w_ci(k10dist_results, label = '$k=10$', line_i =2, x = range(n_iters+1), n_lines = 3)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"k-distance from true ranking\")\n",
    "plt.legend()\n",
    "plt.xlim(left=0, right=n_iters+1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"full_info_k_dist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 2 : KaczRank applied to incomplete information. A fraction p of the full info is sampled and KaczRank is applied for a fixed number of iterations.\n",
    "\n",
    "n = 50\n",
    "n_iters = 10000\n",
    "n_trials = 20\n",
    "eps = 1e-5\n",
    "true_vals = np.random.rand(n)\n",
    "true_rank = get_ranking(true_vals)\n",
    "A = build_adj_mat(true_rank)\n",
    "x_init=np.random.rand(n)\n",
    "\n",
    "ham_results = []\n",
    "k1dist_results = []\n",
    "k5dist_results = []\n",
    "k10dist_results = []\n",
    "ps = np.linspace(0.05, 1, 50)\n",
    "\n",
    "for i in tqdm(range(n_trials)):\n",
    "    ham_temp = []\n",
    "    k1_temp = []\n",
    "    k5_temp = []\n",
    "    k10_temp = []\n",
    "    for p in ps:\n",
    "        rows = np.random.choice(A.shape[0], size = np.floor(p*A.shape[0]).astype(int), replace=False)\n",
    "        A_partial = A[rows,:]\n",
    "        iters, ranks = kaczrank(A_partial, eps, x_init=x_init, n_iters = n_iters)\n",
    "        ham_temp.append(hamdist(ranks[-1,:], true_rank))\n",
    "        k1_temp.append(k_dist(ranks[-1,:], true_rank, 1))\n",
    "        k5_temp.append(k_dist(ranks[-1,:], true_rank, 5))\n",
    "        k10_temp.append(k_dist(ranks[-1,:], true_rank, 10))\n",
    "    ham_results.append(ham_temp)\n",
    "    k1dist_results.append(k1_temp)\n",
    "    k5dist_results.append(k5_temp)\n",
    "    k10dist_results.append(k10_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hamming distance plot\n",
    "plt.clf()\n",
    "plot_average_w_ci(ham_results, x = ps, n_lines = 1)\n",
    "plt.xlabel(\"Fraction of comparisons used\")\n",
    "plt.ylabel(\"Hamming distance from true ranking after 10000 iterations\")\n",
    "plt.xlim(left=0, right=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"partial_info_ham_dist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-distance plot\n",
    "plt.clf()\n",
    "plot_average_w_ci(k1dist_results, label = '$k=1$', line_i = 0, x = ps, n_lines = 3)\n",
    "plot_average_w_ci(k5dist_results, label = '$k=5$', line_i = 1, x = ps, n_lines = 3)\n",
    "plot_average_w_ci(k10dist_results, label = '$k=10$', line_i =2, x = ps, n_lines = 3)\n",
    "plt.xlabel(\"Fraction of comparisons used\")\n",
    "plt.ylabel(\"$k$-distance from true ranking after 10000 iterations\")\n",
    "plt.legend()\n",
    "plt.xlim(left=0, right=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"partial_info_k_dist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 3 : All methods applied to noisy information. Each sample has probability p of being noisy.\n",
    "\n",
    "n = 20\n",
    "n_iters = 10000\n",
    "n_trials = 20\n",
    "eps = 1e-5\n",
    "true_vals = np.random.rand(n)\n",
    "true_rank = get_ranking(true_vals)\n",
    "A = build_adj_mat(true_rank)\n",
    "x_init=np.random.rand(n)\n",
    "\n",
    "kr_ham_results = []\n",
    "kr_k1dist_results = []\n",
    "kr_k5dist_results = []\n",
    "kr_k10dist_results = []\n",
    "\n",
    "cr_ham_results = []\n",
    "cr_k1dist_results = []\n",
    "cr_k5dist_results = []\n",
    "cr_k10dist_results = []\n",
    "\n",
    "ps = np.linspace(0, 0.3, 50)\n",
    "\n",
    "for i in tqdm(range(n_trials)):\n",
    "    kr_ham_temp = []\n",
    "    kr_k1_temp = []\n",
    "    kr_k5_temp = []\n",
    "    kr_k10_temp = []\n",
    "    cr_ham_temp = []\n",
    "    cr_k1_temp = []\n",
    "    cr_k5_temp = []\n",
    "    cr_k10_temp = []\n",
    "\n",
    "    for p in tqdm(ps, leave=False):\n",
    "        kr_iters, kr_ranks = noisykaczrank(A,p, eps, x_init=x_init, n_iters = n_iters)\n",
    "        cr_iters, cr_ranks = cautiousrank(A,p,eps, x_init=x_init, alpha = 4, n_iters = n_iters)\n",
    "        \n",
    "        kr_ham_temp.append(hamdist(kr_ranks[-1,:], true_rank))\n",
    "        kr_k1_temp.append(k_dist(kr_ranks[-1,:], true_rank, 1))\n",
    "        kr_k5_temp.append(k_dist(kr_ranks[-1,:], true_rank, 5))\n",
    "        kr_k10_temp.append(k_dist(kr_ranks[-1,:], true_rank, 10))\n",
    "        cr_ham_temp.append(hamdist(cr_ranks[-1,:], true_rank))\n",
    "        cr_k1_temp.append(k_dist(cr_ranks[-1,:], true_rank, 1))\n",
    "        cr_k5_temp.append(k_dist(cr_ranks[-1,:], true_rank, 5))\n",
    "        cr_k10_temp.append(k_dist(cr_ranks[-1,:], true_rank, 10))\n",
    "        \n",
    "    kr_ham_results.append(kr_ham_temp)\n",
    "    kr_k1dist_results.append(kr_k1_temp)\n",
    "    kr_k5dist_results.append(kr_k5_temp)\n",
    "    kr_k10dist_results.append(kr_k10_temp)\n",
    "    cr_ham_results.append(cr_ham_temp)\n",
    "    cr_k1dist_results.append(cr_k1_temp)\n",
    "    cr_k5dist_results.append(cr_k5_temp)\n",
    "    cr_k10dist_results.append(cr_k10_temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('kr_ham_results.npy', kr_ham_results)\n",
    "np.save('kr_k1dist_results.npy', kr_k1dist_results)\n",
    "np.save('kr_k5dist_results.npy', kr_k5dist_results)\n",
    "np.save('kr_k10dist_results.npy', kr_k10dist_results)\n",
    "np.save('cr_ham_results.npy', cr_ham_results)\n",
    "np.save('cr_k1dist_results.npy', cr_k1dist_results)\n",
    "np.save('cr_k5dist_results.npy', cr_k5dist_results)\n",
    "np.save('cr_k10dist_results.npy', cr_k10dist_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    kr_ham_results = np.load('kr_ham_results.npy')\n",
    "    kr_k1dist_results = np.load('kr_k1dist_results.npy')\n",
    "    kr_k5dist_results = np.load('kr_k5dist_results.npy')\n",
    "    kr_k10dist_results = np.load('kr_k10dist_results.npy')\n",
    "    cr_ham_results = np.load('cr_ham_results.npy')\n",
    "    cr_k1dist_results = np.load('cr_k1dist_results.npy')\n",
    "    cr_k5dist_results = np.load('cr_k5dist_results.npy')\n",
    "    cr_k10dist_results = np.load('cr_k10dist_results.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 6A\n",
    "\n",
    "plt.clf()\n",
    "plot_average_w_ci(kr_ham_results, line_i = 0, x = ps, n_lines = 1)\n",
    "plt.xlabel(\"Probability of flipped comparison\")\n",
    "plt.ylabel(\"Hamming distance from true ranking after 10000 iterations\")\n",
    "plt.xlim(left=0, right=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noisy_kr_hamdist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FIG 6B\n",
    "\n",
    "plt.clf()\n",
    "plot_average_w_ci(cr_ham_results, line_i = 0, x = ps, n_lines = 1)\n",
    "plt.xlabel(\"Probability of flipped comparison\")\n",
    "plt.ylabel(\"Hamming distance from true ranking after 10000 iterations\")\n",
    "plt.xlim(left=0, right=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noisy_cr_hamdist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 6 combined\n",
    "plt.clf()\n",
    "plot_average_w_ci(kr_ham_results, line_i = 0, x = ps, n_lines = 2, label=\"KaczRank\")\n",
    "plot_average_w_ci(cr_ham_results, line_i = 1, x = ps, n_lines = 2, label=\"CautiousRank\")\n",
    "plt.xlabel(\"Probability of flipped comparison\")\n",
    "plt.ylabel(\"Hamming distance from true ranking\")\n",
    "plt.xlim(left=0, right=0.3)\n",
    "plt.ylim(0,20.0)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noisy_kr_cr_hamdist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIG 7A\n",
    "\n",
    "plt.clf()\n",
    "plot_average_w_ci(kr_k1dist_results, label = '$k=1$', line_i = 0, x = ps, n_lines = 3)\n",
    "plot_average_w_ci(kr_k5dist_results, label = '$k=5$', line_i = 1, x = ps, n_lines = 3)\n",
    "plot_average_w_ci(kr_k10dist_results, label = '$k=10$', line_i =2, x = ps, n_lines = 3)\n",
    "plt.xlabel(\"Probability of flipped comparison\")\n",
    "plt.ylabel(\"$k$-distance from true ranking\")\n",
    "plt.legend()\n",
    "plt.xlim(left=0, right=0.3)\n",
    "plt.ylim(0,20.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noisy_kr_k_dist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 7B\n",
    "\n",
    "plt.clf()\n",
    "plot_average_w_ci(cr_k1dist_results, label = '$k=1$', line_i = 0, x = ps, n_lines = 3)\n",
    "plot_average_w_ci(cr_k5dist_results, label = '$k=5$', line_i = 1, x = ps, n_lines = 3)\n",
    "plot_average_w_ci(cr_k10dist_results, label = '$k=10$', line_i =2, x = ps, n_lines = 3)\n",
    "plt.xlabel(\"Probability of flipped comparison\")\n",
    "plt.ylabel(\"$k$-distance from true ranking\")\n",
    "plt.legend()\n",
    "plt.xlim(left=0, right=0.3)\n",
    "plt.ylim(0,20.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noisy_cr_k_dist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 7 combined\n",
    "\n",
    "plt.clf()\n",
    "plot_average_w_ci(kr_k1dist_results, label = 'KR $k=1$', line_i = 0, x = ps, n_lines = 6)\n",
    "plot_average_w_ci(kr_k5dist_results, label = 'KR $k=5$', line_i = 1, x = ps, n_lines = 6)\n",
    "plot_average_w_ci(kr_k10dist_results, label = 'KR $k=10$', line_i =2, x = ps, n_lines = 6)\n",
    "\n",
    "plot_average_w_ci(cr_k1dist_results, label = 'CR $k=1$', line_i = 3, x = ps, n_lines = 6)\n",
    "plot_average_w_ci(cr_k5dist_results, label = 'CR $k=5$', line_i = 4, x = ps, n_lines = 6)\n",
    "plot_average_w_ci(cr_k10dist_results, label = 'CR $k=10$', line_i =5, x = ps, n_lines = 6)\n",
    "plt.xlabel(\"Probability of flipped comparison\")\n",
    "plt.ylabel(\"$k$-distance from true ranking\")\n",
    "plt.legend()\n",
    "plt.xlim(left=0, right=0.3)\n",
    "plt.ylim(0,20.0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noisy_kr_cr_k_dist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 4 : CautiousRank and FrequentRank applied to noisy, incomplete information.\n",
    "\n",
    "n = 20\n",
    "n_iters = 10000\n",
    "n_trials = 20\n",
    "eps = 1e-5\n",
    "true_vals = np.random.rand(n)\n",
    "true_rank = get_ranking(true_vals)\n",
    "A = build_adj_mat(true_rank)\n",
    "x_init=np.random.rand(n)\n",
    "\n",
    "cr_ham_results = []\n",
    "cr_k1dist_results = []\n",
    "cr_k5dist_results = []\n",
    "cr_k10dist_results = []\n",
    "\n",
    "ps = np.linspace(0.05, 1, 50)\n",
    "noisy_prob = 0.05\n",
    "\n",
    "for i in tqdm(range(n_trials)):\n",
    "    cr_ham_temp = []\n",
    "    cr_k1_temp = []\n",
    "    cr_k5_temp = []\n",
    "    cr_k10_temp = []\n",
    "    for p in ps:\n",
    "        rows = np.random.choice(A.shape[0], size = np.floor(p*A.shape[0]).astype(int), replace=False)\n",
    "        A_partial = A[rows,:]\n",
    "        iters, ranks = cautiousrank(A_partial,noisy_prob, eps, x_init=x_init, alpha = 4, n_iters = n_iters)\n",
    "        cr_ham_temp.append(hamdist(ranks[-1,:], true_rank))\n",
    "        cr_k1_temp.append(k_dist(ranks[-1,:], true_rank, 1))\n",
    "        cr_k5_temp.append(k_dist(ranks[-1,:], true_rank, 5))\n",
    "        cr_k10_temp.append(k_dist(ranks[-1,:], true_rank, 10))\n",
    "    cr_ham_results.append(cr_ham_temp)\n",
    "    cr_k1dist_results.append(cr_k1_temp)\n",
    "    cr_k5dist_results.append(cr_k5_temp)\n",
    "    cr_k10dist_results.append(cr_k10_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plot_average_w_ci(cr_ham_results, line_i = 0, x = ps, n_lines = 1)\n",
    "plt.xlabel(\"Fraction of comparisons used\")\n",
    "plt.ylabel(\"Hamming distance from true ranking after 10000 iterations\")\n",
    "plt.xlim(left=0, right=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noisy_incomplete_cr_005_hamdist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plot_average_w_ci(cr_k1dist_results, label = '$k=1$', line_i = 0, x = ps, n_lines = 3)\n",
    "plot_average_w_ci(cr_k5dist_results, label = '$k=5$', line_i = 1, x = ps, n_lines = 3)\n",
    "plot_average_w_ci(cr_k10dist_results, label = '$k=10$', line_i =2, x = ps, n_lines = 3)\n",
    "plt.xlabel(\"Fraction of comparisons used\")\n",
    "plt.ylabel(\"$k$-distance from true ranking after 10000 iterations\")\n",
    "plt.legend()\n",
    "plt.xlim(left=0, right=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"noisy_incomplete_cr_005_kdist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 6: Computing average number of iterations for convergence of KaczRank, for varying numbers of objects.\n",
    "\n",
    "n_trials = 50\n",
    "ns = [5,10,20,50,100,200]\n",
    "eps = 1e-5\n",
    "\n",
    "results = []\n",
    "\n",
    "for n in tqdm(ns):\n",
    "    temp_res = []\n",
    "    eps = 1e-5\n",
    "    true_vals = np.random.rand(n)\n",
    "    true_rank = get_ranking(true_vals)\n",
    "    A = build_adj_mat(true_rank)\n",
    "    for trial in tqdm(range(n_trials)):\n",
    "        ct = kr_itercount(A,eps,x_init=np.random.rand(n))\n",
    "        temp_res.append(ct)\n",
    "    results.append(temp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = sum(temp_res)/len(temp_res)\n",
    "\n",
    "new_temp = temp_res\n",
    "while len(new_temp) < 50:\n",
    "    new_temp.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_arr = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_res = [results_arr[:,i] for i in range(results_arr.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plot_average_w_ci(sorted_res, x = ns, n_lines = 1)\n",
    "plt.xlabel('Number of objects $n$')\n",
    "plt.ylabel('Number of iterations to converge')\n",
    "plt.xlim(left=5, right=200)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"new_log_n_iters_vs_log_n_objects.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 7: Parameter Tuning for CautiousRank\n",
    "\n",
    "n_iters = 10000\n",
    "n = 40\n",
    "eps = 1e-5\n",
    "n_trials = 25\n",
    "alphas = range(1,11)\n",
    "\n",
    "results_005 = []\n",
    "results_010 = []\n",
    "results_020 = []\n",
    "\n",
    "true_vals = np.random.rand(n)\n",
    "true_rank = get_ranking(true_vals)\n",
    "A = build_adj_mat(true_rank)\n",
    "for trial in tqdm(range(n_trials)):\n",
    "    x_init=np.random.rand(n)\n",
    "    trial_res = []\n",
    "    for alpha in alphas:\n",
    "        iters, ranks = cautiousrank(A,0.05, eps, x_init=x_init, alpha =alpha, n_iters = n_iters)\n",
    "        trial_res.append(hamdist(ranks[-1,:], true_rank))\n",
    "    results_005.append(trial_res)\n",
    "\n",
    "for trial in tqdm(range(n_trials)):\n",
    "    x_init=np.random.rand(n)\n",
    "    trial_res = []\n",
    "    for alpha in alphas:\n",
    "        iters, ranks = cautiousrank(A,0.1, eps, x_init=x_init, alpha =alpha, n_iters = n_iters)\n",
    "        trial_res.append(hamdist(ranks[-1,:], true_rank))\n",
    "    results_010.append(trial_res)\n",
    "\n",
    "for trial in tqdm(range(n_trials)):\n",
    "    x_init=np.random.rand(n)\n",
    "    trial_res = []\n",
    "    for alpha in alphas:\n",
    "        iters, ranks = cautiousrank(A,0.2, eps, x_init=x_init, alpha =alpha, n_iters = n_iters)\n",
    "        trial_res.append(hamdist(ranks[-1,:], true_rank))\n",
    "    results_020.append(trial_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_005_arr = np.array(results_005)\n",
    "results_010_arr = np.array(results_010)\n",
    "results_020_arr = np.array(results_020)\n",
    "\n",
    "listed_results_005 = [results_005_arr[i,:] for i in range(results_005_arr.shape[0])]\n",
    "listed_results_010 = [results_010_arr[i,:] for i in range(results_010_arr.shape[0])]\n",
    "listed_results_020 = [results_020_arr[i,:] for i in range(results_020_arr.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plot_average_w_ci(listed_results_005, x = alphas, label = '$p = 0.05$', line_i = 0, n_lines = 3)\n",
    "plot_average_w_ci(listed_results_010, x = alphas, label = '$p = 0.1$', line_i = 1, n_lines = 3)\n",
    "plot_average_w_ci(listed_results_020, x = alphas, label = '$p = 0.2$', line_i = 2, n_lines = 3)\n",
    "plt.xlabel('Cautiousness parameter')\n",
    "plt.ylabel('Hamming distance from true ranking after 10000 iterations')\n",
    "plt.xlim(left=1, right=10)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"hamdist_vs_alpha_cr_n_40.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Last experiment: A comparison of all distance metrics\n",
    "\n",
    "n = 50\n",
    "n_iters = 10000\n",
    "n_trials = 20\n",
    "eps = 1e-5\n",
    "true_vals = np.random.rand(n)\n",
    "true_rank = get_ranking(true_vals)\n",
    "A = build_adj_mat(true_rank)\n",
    "x_init=np.random.rand(n)\n",
    "\n",
    "ham_results = []\n",
    "k5dist_results = []\n",
    "k10dist_results = []\n",
    "ken_tau_results = []\n",
    "cayley_results = []\n",
    "\n",
    "def normalised_cayley_distance(x,y):\n",
    "    B = range(len(x))\n",
    "    inv_y = tuple(y.index(a) for a in B)\n",
    "    comp = tuple(x[inv_y[a]] for a in B)\n",
    "    cycles = 0\n",
    "    rem = set(B)\n",
    "    while rem:\n",
    "        a = rem.pop()\n",
    "        cycles += 1\n",
    "        while comp[a] in rem:\n",
    "            a = comp[a]\n",
    "            rem.remove(a)\n",
    "    return (len(B) - cycles)/(n-1)\n",
    "\n",
    "def normalised_kendall_tau_distance(values1, values2):\n",
    "    \"\"\"Compute the Kendall tau distance.\"\"\"\n",
    "    n = len(values1)\n",
    "    assert len(values2) == n, \"Both lists have to be of equal length\"\n",
    "    i, j = np.meshgrid(np.arange(n), np.arange(n))\n",
    "    a = np.argsort(values1)\n",
    "    b = np.argsort(values2)\n",
    "    ndisordered = np.logical_or(np.logical_and(a[i] < a[j], b[i] > b[j]), np.logical_and(a[i] > a[j], b[i] < b[j])).sum()\n",
    "    return ndisordered / (n * (n - 1))\n",
    "\n",
    "for i in tqdm(range(n_trials)):\n",
    "    iters, ranks = kaczrank(A, eps, x_init=x_init, n_iters = n_iters)\n",
    "    ham_results.append([hamdist(ranks[i,:], true_rank)/n for i in range(ranks.shape[0])])\n",
    "    k5dist_results.append([k_dist(ranks[i,:], true_rank, 5)/n for i in range(ranks.shape[0])])\n",
    "    k10dist_results.append([k_dist(ranks[i,:], true_rank, 10)/n for i in range(ranks.shape[0])])\n",
    "    ken_tau_results.append([normalised_kendall_tau_distance(list(true_vals), list(iters[i,:])) for i in range(ranks.shape[0])])\n",
    "    cayley_results.append([normalised_cayley_distance(list(ranks[i,:].astype(int)), list(true_rank.astype(int))) for i in range(ranks.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plot_average_w_ci(ham_results, x = range(n_iters+1), label = 'Hamming', line_i = 0, n_lines = 5)\n",
    "plot_average_w_ci(k5dist_results, x = range(n_iters+1), label = '$5$-distance', line_i = 1, n_lines = 5)\n",
    "plot_average_w_ci(k10dist_results, x =range(n_iters+1), label = '$10$-distance', line_i = 2, n_lines = 5)\n",
    "plot_average_w_ci(ken_tau_results, x = range(n_iters+1), label = 'Kendall Tau', line_i = 3, n_lines = 5)\n",
    "plot_average_w_ci(cayley_results, x = range(n_iters+1), label = 'Cayley', line_i = 4, n_lines = 5)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Distance from true ranking')\n",
    "plt.xlim(left=1, right=n_iters)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"all_distances.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 8: Cautiousrank time vs. other methods\n",
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "n_iters = 5*10**6\n",
    "ns = np.logspace(np.log10(50), 3.0,25)\n",
    "\n",
    "eps = 1e-5\n",
    "n_trials = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_methods = 4\n",
    "methods = [\"KaczRank\", \"LSR Pairwise\", \"I-LSR Pairwise\", \"Rank Centrality\"]\n",
    "\n",
    "dists = np.zeros((len(ns), n_trials, n_methods))\n",
    "times = np.zeros((len(ns), n_trials, n_methods))\n",
    "memory = np.zeros((len(ns), n_trials, n_methods))\n",
    "iters_per = np.zeros((len(ns), n_trials))\n",
    "\n",
    "# Small fixed delay to make timing more consistent\n",
    "buffer = 1.0\n",
    "\n",
    "\n",
    "for i,n in tqdm(enumerate(ns), total=len(ns)):\n",
    "    n = int(n)\n",
    "    true_vals = np.linspace(0,1,n)\n",
    "    true_rank = get_ranking(true_vals)\n",
    "\n",
    "    A,comps = build_adj_mat(true_rank, make_comps=True, p=0.00)\n",
    "    \n",
    "\n",
    "    \n",
    "    for j, trial in tqdm(enumerate(range(n_trials)), leave=False, total=n_trials):\n",
    "\n",
    "        x_init=np.random.rand(n)\n",
    "        \n",
    "        # KaczRank\n",
    "        tracemalloc.start()\n",
    "        start = time.time()\n",
    "        \n",
    "        kr_rank, iters_out = kaczrank(A,eps,x_init=x_init.copy(),n_iters = 10**8, verbose=False, check_convergence=True)\n",
    "        time.sleep(buffer)\n",
    "        memory[i,j,0] = tracemalloc.get_traced_memory()[1]\n",
    "        \n",
    "        end = time.time()\n",
    "        tracemalloc.stop()\n",
    "        \n",
    "        \n",
    "        kr_rank = get_ranking(kr_rank)\n",
    "        dists[i,j,0] = hamdist(kr_rank, true_rank)\n",
    "        times[i,j,0] = (end - start - buffer)\n",
    "        \n",
    "        iters_per[i,j] = iters_out\n",
    "        \n",
    "        \n",
    "        # LSR Pairwise\n",
    "        tracemalloc.start()\n",
    "        start = time.time()\n",
    "        \n",
    "        rc_rank = lsr_pairwise(n, comps, alpha=1e-4)#, max_iter = 1000)\n",
    "        memory[i,j,1] = tracemalloc.get_traced_memory()[1]\n",
    "        time.sleep(buffer)\n",
    "        end = time.time()\n",
    "        tracemalloc.stop()\n",
    "        \n",
    "        rc_rank = get_ranking(-rc_rank)\n",
    "        dists[i,j,1] = k_dist(rc_rank, true_rank,5)\n",
    "        times[i,j,1] = end - start - buffer\n",
    "        \n",
    "        # ILSR Pairwise\n",
    "        tracemalloc.start()\n",
    "        start = time.time()\n",
    "        \n",
    "        rc_rank = ilsr_pairwise(n, comps, alpha=1e-4, max_iter = 1000)\n",
    "        memory[i,j,2] = tracemalloc.get_traced_memory()[1]\n",
    "        time.sleep(buffer)\n",
    "        end = time.time()\n",
    "        tracemalloc.stop()\n",
    "        \n",
    "        rc_rank = get_ranking(-rc_rank)\n",
    "        dists[i,j,2] = k_dist(rc_rank, true_rank,5)\n",
    "        times[i,j,2] = end - start - buffer\n",
    "        \n",
    "        # Rank Centrality\n",
    "        tracemalloc.start()\n",
    "        start = time.time()\n",
    "        \n",
    "        rc_rank = rank_centrality(n, comps, alpha=1e-4)#, max_iter = 1000)\n",
    "        memory[i,j,3] = tracemalloc.get_traced_memory()[1]\n",
    "        time.sleep(buffer)\n",
    "        end = time.time()\n",
    "        tracemalloc.stop()\n",
    "        \n",
    "        rc_rank = get_ranking(-rc_rank)\n",
    "        dists[i,j,3] = k_dist(rc_rank, true_rank,5)\n",
    "        times[i,j,3] = end - start - buffer\n",
    "        \n",
    "        np.save(f\"last_experiment/experiment_{int(time.time())}.npy\",[dists, times, memory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1,2, dpi=600, figsize=(10,5))\n",
    "for i in range(n_methods):\n",
    "    plot_average_w_ci(times[:,:,i].T, x = ns, label = methods[i], line_i = i, n_lines = n_methods, ax=ax[0])\n",
    "#plot_average_w_ci(kr_times.T, x = ns, label = 'KaczRank', line_i = 0, n_lines = 2, ax=ax[0])\n",
    "#plot_average_w_ci(rc_times.T, x = ns, label = 'LSR Pairwise', line_i = 1, n_lines = 2, ax=ax[0])\n",
    "ax[0].set_xlabel(\"$n$\")\n",
    "ax[0].set_ylabel(\"Computational time to convergence\")\n",
    "ax[0].semilogx()\n",
    "ax[0].semilogy()\n",
    "\n",
    "for i in range(n_methods):\n",
    "    plot_average_w_ci(memory[:,:,i].T, x = ns, label = methods[i], line_i = i, n_lines = n_methods, ax=ax[1])\n",
    "#plot_average_w_ci(kr_mem.T, x = ns, label = 'KaczRank', line_i = 0, n_lines = 2, ax=ax[1])\n",
    "#plot_average_w_ci(rc_mem.T, x = ns, label = 'LSR Pairwise', line_i = 1, n_lines = 2, ax=ax[1])\n",
    "ax[1].set_xlabel(\"$n$\")\n",
    "ax[1].set_ylabel(\"Max. memory usage\")\n",
    "ax[1].semilogx()\n",
    "ax[1].semilogy()\n",
    "ax[1].legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"kr_vs_all_mem.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.clf()\n",
    "for i in range(n_methods):\n",
    "    plot_average_w_ci(times[:,:,i].T, x = ns, label = methods[i], line_i = i, n_lines = n_methods)\n",
    "#plot_average_w_ci(kr_times.T, x = ns, label = 'KaczRank', line_i = 0, n_lines = 2, ax=ax[0])\n",
    "#plot_average_w_ci(rc_times.T, x = ns, label = 'LSR Pairwise', line_i = 1, n_lines = 2, ax=ax[0])\n",
    "plt.xlabel(\"$n$\")\n",
    "plt.ylabel(\"Computational time to convergence\")\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(\"new_kr_vs_all_time.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.clf()\n",
    "for i in range(n_methods):\n",
    "    plot_average_w_ci(memory[:,:,i].T, x = ns, label = methods[i], line_i = i, n_lines = n_methods)\n",
    "#plot_average_w_ci(kr_times.T, x = ns, label = 'KaczRank', line_i = 0, n_lines = 2, ax=ax[0])\n",
    "#plot_average_w_ci(rc_times.T, x = ns, label = 'LSR Pairwise', line_i = 1, n_lines = 2, ax=ax[0])\n",
    "plt.xlabel(\"$n$\")\n",
    "plt.ylabel(\"Max. memory usage\")\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"new_kr_vs_all_memory.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
